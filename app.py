import streamlit as st
import pandas as pd
import google.generativeai as genai

# é é¢è¨­å®š
st.set_page_config(page_title="Gemini èŠå¤©å®¤", layout="wide")
st.title("ğŸ¤– Gemini AI èŠå¤©å®¤ + ğŸ“ CSV ä¸Šå‚³")

# å–å¾—ä½¿ç”¨è€…è¼¸å…¥çš„ API é‡‘é‘°
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

st.sidebar.header("ğŸ”‘ è¼¸å…¥ Gemini API é‡‘é‘°")
api_key_input = st.sidebar.text_input("è«‹è¼¸å…¥ä½ çš„ API é‡‘é‘°", type="password")
if api_key_input:
    st.session_state.api_key = api_key_input

# æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦å­˜åœ¨
if not st.session_state.api_key:
    st.warning("âš ï¸ è«‹åœ¨å·¦å´è¼¸å…¥æœ‰æ•ˆçš„ Gemini API é‡‘é‘°å¾Œä½¿ç”¨æœ¬ç³»çµ±ã€‚")
    st.stop()

# è¨­å®š Gemini
try:
    genai.configure(api_key=st.session_state.api_key)
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"API é‡‘é‘°è¨­å®šå¤±æ•—ï¼š{e}")
    st.stop()

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ğŸ“ CSV ä¸Šå‚³åŠŸèƒ½
st.subheader("ğŸ“‚ ä¸Šå‚³ CSV æª”æ¡ˆ")
uploaded_file = st.file_uploader("è«‹é¸æ“‡ä¸€å€‹ CSV æª”æ¡ˆ", type="csv")
if uploaded_file:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("âœ… æˆåŠŸä¸Šå‚³ï¼ä»¥ä¸‹æ˜¯è³‡æ–™é è¦½ï¼š")

        # é¡¯ç¤ºæ¬„ä½é¸æ“‡å™¨
        selected_columns = st.multiselect("ğŸ“Œ è«‹é¸æ“‡è¦ä½¿ç”¨çš„æ¬„ä½", df.columns.tolist(), default=df.columns.tolist())

        # æŒ‰éˆ•å€ï¼šé¸æ“‡åœ–è¡¨é¡å‹
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            show_table = st.button("ğŸ“‹ é¡¯ç¤ºè³‡æ–™è¡¨")
        with col2:
            show_bar = st.button("ğŸ“Š é•·æ¢åœ–")
        with col3:
            show_pie = st.button("ğŸ¥§ åœ“é¤…åœ–")
        with col4:
            show_line = st.button("ğŸ“ˆ æŠ˜ç·šåœ–")

        # è³‡æ–™ç¯©é¸
        if selected_columns:
            filtered_df = df[selected_columns]
        else:
            st.warning("âš ï¸ è«‹é¸æ“‡è‡³å°‘ä¸€å€‹æ¬„ä½")
            st.stop()

        # é¡¯ç¤ºè¡¨æ ¼
        if show_table:
            st.subheader("ğŸ“‹ è³‡æ–™è¡¨")
            st.dataframe(filtered_df)

        # é¡¯ç¤ºé•·æ¢åœ–ï¼ˆé™é¡åˆ¥ + æ•¸å€¼ï¼‰
        if show_bar:
            st.subheader("ğŸ“Š é•·æ¢åœ–")
            if len(selected_columns) >= 2:
                st.bar_chart(filtered_df)
            else:
                st.warning("âš ï¸ è«‹é¸æ“‡å…©å€‹ä»¥ä¸Šæ¬„ä½ä¾†ç•«é•·æ¢åœ–")

        # é¡¯ç¤ºåœ“é¤…åœ–ï¼ˆåªæ”¯æ´ä¸€æ¬„é¡åˆ¥ã€ä¸€æ¬„æ•¸å€¼ï¼‰
        if show_pie:
            st.subheader("ğŸ¥§ åœ“é¤…åœ–")
            if len(selected_columns) == 2:
                cat_col, val_col = selected_columns
                pie_data = df.groupby(cat_col)[val_col].sum().reset_index()
                fig_pie = px.pie(pie_data, names=cat_col, values=val_col, title="åœ“é¤…åœ–")
                st.plotly_chart(fig_pie)
            else:
                st.warning("âš ï¸ åœ“é¤…åœ–éœ€é¸æ“‡ 1 å€‹é¡åˆ¥æ¬„ä½ + 1 å€‹æ•¸å€¼æ¬„ä½")

        # é¡¯ç¤ºæŠ˜ç·šåœ–ï¼ˆé€šå¸¸ç”¨æ–¼æ™‚é–“åºåˆ—ï¼‰
        if show_line:
            st.subheader("ğŸ“ˆ æŠ˜ç·šåœ–")
            st.line_chart(filtered_df)

    except Exception as e:
        st.error(f"CSV è®€å–éŒ¯èª¤ï¼š{e}")


# ğŸ§  å´é‚Šæ¬„ï¼šè¨˜æ†¶ç•™å­˜å€
with st.sidebar:
    st.header("ğŸ§  è¨˜æ†¶ç•™å­˜å€")
    if st.session_state.chat_history:
        for msg in st.session_state.chat_history:
            st.markdown(f"ğŸ‘¤ **ä½ ï¼š** {msg['user']}")
            st.markdown(f"ğŸ¤– **AIï¼š** {msg['ai']}")
            st.markdown("---")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±ç´€éŒ„"):
            st.session_state.chat_history = []
            st.experimental_rerun()
    else:
        st.info("ç›®å‰æ²’æœ‰å°è©±ç´€éŒ„ã€‚")

# ğŸ’¬ èŠå¤©ä»‹é¢
st.subheader("ğŸ’¬ Gemini AI å°è©±å€")

# é¡¯ç¤ºèŠå¤©æ°£æ³¡
for msg in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(msg["user"])
    with st.chat_message("ai"):
        st.markdown(msg["ai"])

# è¼¸å…¥å°è©±
if prompt := st.chat_input("è¼¸å…¥ä½ çš„å•é¡Œ..."):
    # é¡¯ç¤ºè‡ªå·±çš„è¨Šæ¯
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gemini å›æ‡‰
    with st.chat_message("ai"):
        with st.spinner("Gemini æ€è€ƒä¸­..."):
            try:
                response = model.generate_content(prompt)
                ai_text = response.text
                st.markdown(ai_text)

                # å„²å­˜å°è©±ç´€éŒ„
                st.session_state.chat_history.append({
                    "user": prompt,
                    "ai": ai_text
                })
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
