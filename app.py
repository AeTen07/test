import streamlit as st
import pandas as pd
import google.generativeai as genai

# é é¢è¨­å®š
st.set_page_config(page_title="Gemini èŠå¤©å®¤", layout="wide")
st.title("ğŸ¤– Gemini AI èŠå¤©å®¤ + ğŸ“ CSV ä¸Šå‚³")

# å–å¾—ä½¿ç”¨è€…è¼¸å…¥çš„ API é‡‘é‘°
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

st.sidebar.header("ğŸ”‘ è¼¸å…¥ Gemini API é‡‘é‘°")
api_key_input = st.sidebar.text_input("è«‹è¼¸å…¥ä½ çš„ API é‡‘é‘°", type="password")
if api_key_input:
    st.session_state.api_key = api_key_input

# æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦å­˜åœ¨
if not st.session_state.api_key:
    st.warning("âš ï¸ è«‹åœ¨å·¦å´è¼¸å…¥æœ‰æ•ˆçš„ Gemini API é‡‘é‘°å¾Œä½¿ç”¨æœ¬ç³»çµ±ã€‚")
    st.stop()

# è¨­å®š Gemini
try:
    genai.configure(api_key=st.session_state.api_key)
    model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"API é‡‘é‘°è¨­å®šå¤±æ•—ï¼š{e}")
    st.stop()

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ğŸ“ CSV ä¸Šå‚³åŠŸèƒ½
st.subheader("ğŸ“‚ ä¸Šå‚³ CSV æª”æ¡ˆ")
uploaded_file = st.file_uploader("è«‹é¸æ“‡ä¸€å€‹ CSV æª”æ¡ˆ", type="csv")
if uploaded_file:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("âœ… æˆåŠŸä¸Šå‚³ï¼ä»¥ä¸‹æ˜¯è³‡æ–™é è¦½ï¼š")
        st.dataframe(df)
    except Exception as e:
        st.error(f"CSV è®€å–éŒ¯èª¤ï¼š{e}")

# ğŸ§  å´é‚Šæ¬„ï¼šè¨˜æ†¶ç•™å­˜å€
with st.sidebar:
    st.header("ğŸ§  è¨˜æ†¶ç•™å­˜å€")
    if st.session_state.chat_history:
        for msg in st.session_state.chat_history:
            st.markdown(f"ğŸ‘¤ **ä½ ï¼š** {msg['user']}")
            st.markdown(f"ğŸ¤– **AIï¼š** {msg['ai']}")
            st.markdown("---")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±ç´€éŒ„"):
            st.session_state.chat_history = []
            st.experimental_rerun()
    else:
        st.info("ç›®å‰æ²’æœ‰å°è©±ç´€éŒ„ã€‚")

# ğŸ’¬ èŠå¤©ä»‹é¢
st.subheader("ğŸ’¬ Gemini AI å°è©±å€")

# é¡¯ç¤ºèŠå¤©æ°£æ³¡
for msg in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(msg["user"])
    with st.chat_message("ai"):
        st.markdown(msg["ai"])

# è¼¸å…¥å°è©±
if prompt := st.chat_input("è¼¸å…¥ä½ çš„å•é¡Œ..."):
    # é¡¯ç¤ºè‡ªå·±çš„è¨Šæ¯
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gemini å›æ‡‰
    with st.chat_message("ai"):
        with st.spinner("Gemini æ€è€ƒä¸­..."):
            try:
                response = model.generate_content(prompt)
                ai_text = response.text
                st.markdown(ai_text)

                # å„²å­˜å°è©±ç´€éŒ„
                st.session_state.chat_history.append({
                    "user": prompt,
                    "ai": ai_text
                })
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
