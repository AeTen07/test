import streamlit as st
import os
from dotenv import load_dotenv
import google.generativeai as genai
from PIL import Image

# è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

# è¨­å®š Gemini API é‡‘é‘°
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-pro')

# è¨­å®šç¶²é æ¨™é¡Œèˆ‡icon
st.set_page_config(page_title="Gemini èŠå¤©å®¤", page_icon="ğŸ¤–")
st.title("ğŸ¤– Gemini AI èŠå¤©å®¤")
st.markdown("## ğŸ’¬ Gemini AI å°è©±å€")

# æ’å…¥è‡ªå®š CSSï¼šå›ºå®šè¼¸å…¥æ¬„åœ¨åº•éƒ¨
st.markdown("""
<style>
div[data-testid="stChatInput"] {
    position: fixed;
    bottom: 20px;
    width: 85%;
    z-index: 100;
    background-color: white;
    padding-bottom: 20px;
}
</style>
""", unsafe_allow_html=True)

# å»ºç«‹èŠå¤©æ­·å²ç´€éŒ„
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.chat_history:
    with st.chat_message("user"):
        st.markdown(msg["user"])
        if msg.get("image"):
            st.image(msg["image"], caption="ä½ ä¸Šå‚³çš„åœ–ç‰‡", use_column_width=True)
    with st.chat_message("ai"):
        st.markdown(msg["ai"])

# ä½¿ç”¨è€…è¼¸å…¥
prompt = st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œ...")

# æª”æ¡ˆä¸Šå‚³æ”¾åœ¨æœ€åº•éƒ¨å€å¡Š
with st.container():
    uploaded_image = st.file_uploader("ğŸ–¼ï¸ ä¸Šå‚³åœ–ç‰‡", type=["png", "jpg", "jpeg", "webp"], label_visibility="visible")

# åˆ¤æ–·æ˜¯å¦é€å‡ºè¨Šæ¯æˆ–åœ–ç‰‡
if prompt or uploaded_image:
    # å„²å­˜ä½¿ç”¨è€…è¨Šæ¯
    user_msg = {"user": prompt, "image": None}
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_image:
            image = Image.open(uploaded_image)
            st.image(image, caption="ä½ ä¸Šå‚³çš„åœ–ç‰‡", use_column_width=True)
            user_msg["image"] = image

    # Gemini å›è¦†
    with st.chat_message("ai"):
        with st.spinner("Gemini æ€è€ƒä¸­..."):
            if uploaded_image:
                img_data = genai.upload_file(uploaded_image.name, uploaded_image.read())
                response = model.generate_content([prompt, img_data])
            else:
                response = model.generate_content(prompt)
        st.markdown(response.text)

    # å„²å­˜å°è©±ç´€éŒ„
    ai_msg = {"user": prompt, "image": user_msg["image"], "ai": response.text}
    st.session_state.chat_history.append(ai_msg)
